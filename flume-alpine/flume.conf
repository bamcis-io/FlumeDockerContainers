FLUME_AGENT_NAME.sources = kafka-source-1
FLUME_AGENT_NAME.channels = kafka-channel-1
FLUME_AGENT_NAME.sinks = hdfs-sink-1

FLUME_AGENT_NAME.sources.kafka-source-1.type = org.apache.flume.source.kafka.KafkaSource
FLUME_AGENT_NAME.sources.kafka-source-1.channels = kafka-channel-1
FLUME_AGENT_NAME.sources.kafka-source-1.kafka.bootstrap.servers = ${KAFKA_SERVERS}
FLUME_AGENT_NAME.sources.kafka-source-1.kafka.topics.regex = ^.*$
FLUME_AGENT_NAME.sources.kafka-source-1.kafka.consumer.group.id = flume
FLUME_AGENT_NAME.sources.kafka-source-1.interceptors = timestamp-interceptor host-interceptor
FLUME_AGENT_NAME.sources.kafka-source-1.interceptors.timestamp-interceptor.type = timestamp
FLUME_AGENT_NAME.sources.kafka-source-1.interceptors.host-interceptor.type = host

FLUME_AGENT_NAME.channels.kafka-channel-1.type = memory
FLUME_AGENT_NAME.channels.kafka-channel-1.capacity = 10000
FLUME_AGENT_NAME.channels.kafka-channel-1.transactionCapacity = 1000

FLUME_AGENT_NAME.sinks.hdfs-sink-1.type = hdfs
FLUME_AGENT_NAME.sinks.hdfs-sink-1.hdfs.path = hdfs://${HDFS_NAMENODE}/raw/%Y/%m/%{topic}
FLUME_AGENT_NAME.sinks.hdfs-sink-1.hdfs.filePrefix = %Y-%m-%d-%{host}-%{topic}
FLUME_AGENT_NAME.sinks.hdfs-sink-1.hdfs.fileSuffix = .avro
# Disable rollover so we write all of the data from a topic to the same file
FLUME_AGENT_NAME.sinks.hdfs-sink-1.hdfs.rollInterval = 0
FLUME_AGENT_NAME.sinks.hdfs-sink-1.hdfs.rollSize = 0
FLUME_AGENT_NAME.sinks.hdfs-sink-1.hdfs.rollCount = 0
FLUME_AGENT_NAME.sinks.hdfs-sink-1.hdfs.fileType = DataStream
FLUME_AGENT_NAME.sinks.hdfs-sink-1.hdfs.writeFormat = Text
FLUME_AGENT_NAME.sinks.hdfs-sink-1.serializer = avro_event
FLUME_AGENT_NAME.sinks.hdfs-sink-1.serializer.compressionCodec = snappy
FLUME_AGENT_NAME.sinks.hdfs-sink-1.channel = kafka-channel-1